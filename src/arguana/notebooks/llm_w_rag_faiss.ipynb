{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d450d4-a778-4e79-aee4-d061c102d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import LlamaCpp, OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5a6fe4-35df-4bdf-8a60-4ae947b448fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI's API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187e6767-aa2e-4272-aace-a07a04a9f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents' texts\n",
    "with open(\"../dataset/documents.pkl\", \"rb\") as f:\n",
    "    docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e76d74-c3a6-4f26-8e0c-a3019e136e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load queries' text\n",
    "with open(\"../dataset/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92610100-a442-418c-9a09-323164c73893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "with open(\"../dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    rel_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676dfb3-c926-4fa2-8391-b6bb5f10350a",
   "metadata": {},
   "source": [
    "### Common Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8c11992-2bb2-4c2f-ab9c-bede9b2ff17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10  # Choose the top-k most relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f69aa0c-cf65-4d74-be38-f2d917b1ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index from file\n",
    "faiss_vs = FAISS.load_local(\n",
    "    folder_path=\"../ir_techniques/faiss/\",\n",
    "    embeddings=OpenAIEmbeddings())\n",
    "retriever = faiss_vs.as_retriever(search_kwargs={\"k\": k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8982461-b87a-47c1-a66a-d4ba3e897337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(_docs):\n",
    "    ls = []\n",
    "    for doc in _docs:\n",
    "        if int(doc.page_content) in docs:\n",
    "            ls.append(docs[int(doc.page_content)][\"text\"])\n",
    "    return ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f996be53-ee01-46eb-a953-46f23881930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for the LLM\n",
    "template = \"\"\"Answer the question or Explain the topic given this additional context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303176b7-be55-4c05-93a4-92afadf7d220",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb3f52b2-dc0b-4a7c-b086-3b9f689345fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM\n",
    "gpt_llm = OpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "917881c1-8857-4ac1-81b8-b28fd04f08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG pipeline\n",
    "gpt_chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}  \n",
    "             | prompt \n",
    "             | gpt_llm \n",
    "             | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d06ba5e-1c0c-425b-92b7-9bed50d0b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a query\n",
    "# gpt_chain.invoke(queries[1][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c8c838-2c38-4bd3-89e5-690a824d5815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking Queries to ChatGPT with RAG:   0%|                             | 0/76 [00:04<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#### API CALL WARNING #####\n",
    "\n",
    "# Run RAG pipeline for every query\n",
    "answers_gpt = {}\n",
    "for query_id in tqdm(rel_set.keys(), desc=\"Asking Queries to ChatGPT with RAG\"):\n",
    "    response = gpt_chain.invoke(queries[query_id][\"text\"])\n",
    "    answers_gpt[query_id] = {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4071e898-e30e-4928-bbea-493f94fe1b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?',\n",
       " '\\nAnswer: There are several problems and concerns in making up descriptive titles for articles in engineering literature. One issue is the proportion of information that is contained in the complete document but cannot be deduced from the title alone. This means that even if a title is descriptive and informative, there may still be important information missing that is only found in the full document. Additionally, there are challenges in dealing with synonyms and syntactical variants in titles when searching indexes.\\n\\nAnother difficulty is the effectiveness of titles in conveying the relevance of an article to potential users. While titles are important for alerting and information services, they may not accurately represent the content of the article and therefore may not be useful in determining relevance. This can lead to missed opportunities for users who rely solely on titles for information.\\n\\nAutomatically retrieving articles from approximate titles also presents challenges. Even if all possible synonyms and related terms are used, between one-third and one-half of indexable terms may not be retrievable from article titles. This means that users may miss out on relevant articles if they only use approximate titles for their searches.\\n\\nIn general, there is a close relationship between the content of articles and their titles. However, the relevance of the content to the title can vary. Some titles may be more informative and accurately reflect')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "queries[1][\"text\"], answers_gpt[1][\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "275c28b5-fd3e-47fb-8e33-26ed42ecd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all responses\n",
    "with open(\"../responses/gpt-3.5-turbo-instruct/llm_w_rag_faiss.pkl\", \"wb\") as f:\n",
    "    pickle.dump(answers_gpt, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
