{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d450d4-a778-4e79-aee4-d061c102d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de2cd29-c1f6-4a98-b843-c2fc4961c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Uncomment to use the default DaVinci Model \n",
    "# llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# model = 'text-davinci-003'\n",
    "\n",
    "# Uncomment to use the gpt-3.5-turbo-instruct model \n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "model = 'gpt-3.5-turbo-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a1864e-1407-419a-a5a6-9643a32c4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return word_tokenize(text.lower())\n",
    "queries = {}\n",
    "\n",
    "idx = None\n",
    "with open(\"../data/cisi/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = \"\"\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx] += \" \"+line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8944e68a-04f8-48f6-b74f-795a5aea06ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53d7d888-6520-4f05-a471-693db3de55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document embeddings loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "docs_file_path = './backups/openai_embeddings/doc_embeddings.pkl'\n",
    "\n",
    "with open(docs_file_path, 'rb') as file:\n",
    "    docs = pickle.load(file)\n",
    "\n",
    "print(\"Document embeddings loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6126b150-171e-47fb-834f-2e2bcb8720bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".W\\n   The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30166860-696f-4f6d-8a80-80607694bbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_set = {}\n",
    "with open(os.path.join(\"../data/cisi/\", 'CISI.REL')) as f:\n",
    "    for l in f.readlines():\n",
    "        qry_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[0]\n",
    "        doc_id = l.lstrip(\" \").strip(\"\\n\").split(\"\\t\")[0].split(\" \")[-1]\n",
    "\n",
    "        if qry_id in rel_set:\n",
    "            rel_set[qry_id].append(doc_id)\n",
    "        else:\n",
    "            rel_set[qry_id] = []\n",
    "            rel_set[qry_id].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421ca38-aca4-4e33-8c84-52f0c3b43d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_data = []\n",
    "for doc in loaded_docs:\n",
    "    annoy_data.append((doc[\"id\"], doc[\"embedding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf7824d-e44a-4af9-b2bd-43604a5d22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vs = FAISS.from_embeddings(\n",
    "    text_embeddings=annoy_data, \n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    distance_strategy=DistanceStrategy.DOT_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64f904-79a3-4a44-9582-df1170a23bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vs.save_local(\"./backups/faiss/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e00668d4-0650-4dd5-934a-2bca0a29f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index from file\n",
    "loaded_faiss_vs = FAISS.load_local(\n",
    "    folder_path=\"./backups/faiss/\",\n",
    "    embeddings=OpenAIEmbeddings())\n",
    "\n",
    "retriever = loaded_faiss_vs.as_retriever(search_kwargs={'k': 10})\n",
    "\n",
    "# Define the RAG pipeline\n",
    "template = \"\"\"\n",
    "Answer the question or Explain the topic given this additional context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7a5756-298f-425d-be0e-8816c168a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(_docs):\n",
    "    ls = []\n",
    "    for doc in _docs:\n",
    "        if int(doc.page_content) in docs:\n",
    "            ls.append(docs[int(doc.page_content)][\"body\"])\n",
    "    return ls\n",
    "    # return [docs[int(doc.page_content)][\"body\"] for doc in _docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b67855-db6b-42a7-8c38-20ca81eaaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "         | prompt \n",
    "         | llm \n",
    "         | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31ab46da-3217-41c2-aa0f-6518e6935a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe Technology of Library and Information Networks is a topic that explores the various technologies used to facilitate the storage, retrieval, and dissemination of information in libraries. This includes physical infrastructure such as servers and routers, as well as software systems that enable the organization and search of information. \\n\\nIn the context of this article, the focus is on online library network technology. This refers to the use of computer networks and internet technology to connect libraries and allow for the sharing of resources and information. The article distinguishes between three types of library networks: search services, customized services, and service centers. \\n\\nSearch services, provided by companies like SDC and Lockheed, allow users to search for information across multiple libraries and databases. This enables more efficient and comprehensive access to information. \\n\\nCustomized services, offered by organizations like OCLC and RLIN, provide access to bibliographic files and other specialized resources. These services are tailored to the needs of specific libraries and their users. \\n\\nService centers, such as NELINET and INCOLSA, act as intermediaries between libraries and provide support for various network operations. They often offer training, technical support, and other services to help libraries utilize network technology effectively. \\n\\nThe article also predicts that as technology continues to evolve, more services will be'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(queries[66])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba9db072-d4e4-4e3a-bff5-735e79954315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking Queries to ChatGPT with RAG: 100%|██████████████████████████████| 76/76 [04:35<00:00,  3.63s/it]\n"
     ]
    }
   ],
   "source": [
    "#### API CALL WARNING #####\n",
    "\n",
    "rag_responses = {}\n",
    "loq = []\n",
    "# Run RAG pipeline for every question\n",
    "for query_id in tqdm(rel_set.keys(), desc = 'Asking Queries to ChatGPT with RAG'):\n",
    "    query_text = queries[int(query_id)]\n",
    "    response = chain.invoke(query_text)\n",
    "    rag_responses[query_id] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89478ca1-3feb-43e0-83a5-d346aa677657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Searching Biases in Large Interactive Document Retrieval Systems Blair, D.C.     The way that individuals construct and modify search queries on a large interactive document retrieval system is subject to systematic biases similar to those that have been demonstrated in experiments on judgements under uncertainty.  These biases are shared by both naive and sophisticated subjects and cause the inquirer searching for documents on a large interactive system to construct and modify queries inefficiently.  A searching algorithm is suggested that helps the inquirer to avoid the effect of these biases. (JASIS, Vol. 31, No. 4, July 1980, pp. 271-277)\n"
     ]
    }
   ],
   "source": [
    "print(queries[61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7a72be-5f6b-446e-bb7b-63ad8a8d31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG responses saved to ./backups/openai_with_rag_responsesgpt-3.5-turbo-instruct.pkl\n"
     ]
    }
   ],
   "source": [
    "#### DUMP OVERWRITE WARNING ####\n",
    "\n",
    "rag_responses_file_path = './backups/openai_with_rag_responses_' + model + '.pkl'\n",
    "with open(rag_responses_file_path, 'wb') as file:\n",
    "    pickle.dump(rag_responses, file)\n",
    "\n",
    "print(f\"RAG responses saved to {rag_responses_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69543307-aca1-4247-94a8-1cd6dd983553",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_with_rag_responses_file_path = './backups/openai_with_rag_responses_' + model + '.pkl'\n",
    "with open(openai_with_rag_responses_file_path, 'rb') as file:\n",
    "    rag_responses = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "694673f9-44bb-47ff-9fc6-1045afff7035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCo-Citation Context Analysis is a method used to identify and analyze paradigms in information science. This method involves using citation analysis techniques to identify patterns in the use of specific concepts within a set of papers pertaining to a particular topic. The identified concepts are then mapped onto a graph, with each concept represented as a node and their relationships represented as lines connecting them. This graph displays the structure of the concepts and the frequency of their occurrence, providing a measure of consensus within the corpus.\\n\\nThe purpose of this approach is to identify and understand the intellectual perspectives or paradigms that exist within a particular field of study. These paradigms are often shared by groups of scientists, known as invisible colleges, who are in frequent communication with one another and have specialized knowledge in a specific subject matter.\\n\\nTo operationalize the notion of paradigms, the paper proposes the concept of a \"consensual structure of concepts in a field.\" This means that there is a general agreement among scientists on the use and combination of certain concepts within the corpus. For example, if two concepts, A and B, are frequently used together in a specific manner within the papers, it can be considered a consensus within the corpus.\\n\\nThe identified structure of concepts can be displayed as a graph, with the frequency'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Sanity\n",
    "rag_responses['90']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecff5f07-b4d6-4e54-bf87-0d851c3ae049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\".W\\n   The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e89275-062c-49f8-ab9b-ad6bd50f4c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU Score: 0.7937\n",
      "Mean ROUGE Score: 0.2425\n"
     ]
    }
   ],
   "source": [
    "# Implement BLEU evaluation function\n",
    "def compute_bleu(references, candidate):\n",
    "    smoothing = SmoothingFunction().method0\n",
    "    return sentence_bleu(references, candidate, smoothing_function=smoothing)\n",
    "\n",
    "# Implement ROUGE evaluation function\n",
    "def compute_rouge(references, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    total_score = 0\n",
    "\n",
    "    # Compute ROUGE for each reference\n",
    "    for reference in references:\n",
    "        scores = scorer.score(reference, candidate)\n",
    "        total_score += scores['rouge1'].fmeasure\n",
    "\n",
    "    # Calculate average score\n",
    "    average_score = total_score / len(references)\n",
    "    return average_score\n",
    "\n",
    "# Evaluate BLEU and ROUGE for each query\n",
    "\n",
    "K = 30 # Number of most relevant docs to consider for scoring performance\n",
    "total_bleu_score = 0.0\n",
    "total_rouge_score = 0.0\n",
    "num_queries = 0\n",
    "\n",
    "for query_id, relevant_docs in rel_set.items():\n",
    "    query_text = queries[int(query_id)]\n",
    "    response = rag_responses[query_id]\n",
    "\n",
    "    # print(query_id, query_text, \"\\n\\nResponse:\\n\", response, \"\\nTopmost relevant Doc:\\n\", docs[int(relevant_docs[0])], \"\\n======\\n\")\n",
    "    \n",
    "    # Evaluate using BLEU\n",
    "    bleu_score = compute_bleu([docs[int(id)]['body'] for id in relevant_docs[:K]], response)\n",
    "    total_bleu_score += bleu_score\n",
    "\n",
    "    # Evaluate using ROUGE\n",
    "    rouge_score = compute_rouge([docs[int(id)]['body'] for id in relevant_docs[:K]], response)\n",
    "    total_rouge_score += rouge_score\n",
    "\n",
    "    num_queries += 1\n",
    "    # if num_queries == 10:\n",
    "    #     break\n",
    "\n",
    "# Calculate mean scores\n",
    "mean_bleu_score = total_bleu_score / num_queries\n",
    "mean_rouge_score = total_rouge_score / num_queries\n",
    "\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b95aab-2ac2-404f-ba82-55a06e8ae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da-vinci\n",
    "# Mean BLEU Score: 0.8224\n",
    "# Mean ROUGE Score: 0.2105\n",
    "\n",
    "# Mean BLEU Score: 0.8377\n",
    "# Mean ROUGE Score: 0.2226\n",
    "\n",
    "# gpt-3.5-turbo-instruct\n",
    "\n",
    "# Mean BLEU Score: 0.7869\n",
    "# Mean ROUGE Score: 0.2407\n",
    "\n",
    "# Mean BLEU Score: 0.7937\n",
    "# Mean ROUGE Score: 0.2425\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
