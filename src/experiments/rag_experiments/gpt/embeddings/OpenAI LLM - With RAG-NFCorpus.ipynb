{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53d450d4-a778-4e79-aee4-d061c102d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.vectorstores.utils import DistanceStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4de2cd29-c1f6-4a98-b843-c2fc4961c6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Uncomment to use the default DaVinci Model \n",
    "# llm = OpenAI(openai_api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# model = 'text-davinci-003'\n",
    "\n",
    "# Uncomment to use the gpt-3.5-turbo-instruct model \n",
    "llm = OpenAI(model_name='gpt-3.5-turbo-instruct', openai_api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "model = 'gpt-3.5-turbo-instruct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8944e68a-04f8-48f6-b74f-795a5aea06ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "\n",
    "dataset = ir_datasets.load(\"beir/nfcorpus/test\")\n",
    "\n",
    "\n",
    "queries = {}\n",
    "for query in dataset.queries_iter():\n",
    "    queries[query.query_id] = {\"text\":query.text}\n",
    "\n",
    "docs = {}\n",
    "count = 0\n",
    "for doc in dataset.docs_iter():\n",
    "    docs[doc.doc_id] = {\"text\": doc.text}\n",
    "    count += 1\n",
    "\n",
    "rel_set = {}\n",
    "for qrel in dataset.qrels_iter():\n",
    "    if qrel.query_id not in rel_set:\n",
    "        rel_set[qrel.query_id] = []\n",
    "    if qrel.relevance > 0: \n",
    "        rel_set[qrel.query_id].append(qrel.doc_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "739ddf97-66dc-48dc-ab49-8b8851e9662b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'Do Cholesterol Statin Drugs Cause Breast Cancer?'}, 323)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries['PLAIN-2'], len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec0422a-80ad-4471-9e0f-eaec6a645a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': 'Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. After adjustment for age, tumor characteristics, and treatment selection, both post-diagnostic and pre-diagnostic statin use were associated with lowered risk of breast cancer death (HR 0.46, 95% CI 0.38–0.55 and HR 0.54, 95% CI 0.44–0.67, respectively). The risk decrease by post-diagnostic statin use was likely affected by healthy adherer bias; that is, the greater likelihood of dying cancer patients to discontinue statin use as the association was not clearly dose-dependent and observed already at low-dose/short-term use. The dose- and time-dependence of the survival benefit among pre-diagnostic statin users suggests a possible causal effect that should be evaluated further in a clinical trial testing statins’ effect on survival in breast cancer patients.'},\n",
       " 3633)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs['MED-10'], len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c070a34-ae77-4aff-bc9a-015206f6bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### API CALL WARNING ####\n",
    "\n",
    "client = openai.OpenAI(api_key = os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-ada-002\"):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    response = client.embeddings.create(input=[text], model=model)\n",
    "    if response and hasattr(response, 'data') and response.data:\n",
    "        embedding = response.data[0].embedding\n",
    "        return embedding\n",
    "    else:\n",
    "        print(\"Invalid response or no embedding data received.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87fd08b4-f91b-4f4f-824b-b81ff3c89aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|███████████████████████████████| 323/323 [00:57<00:00,  5.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for idx, query in tqdm(queries.items(), desc = 'Generating Embeddings'):\n",
    "    query_text = query['text']\n",
    "    queries[idx] = {'text': query_text, 'embedding': get_embedding(query_text)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c592887b-344b-4b7b-a954-1f1d30ed528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|█████████████████████████████| 3633/3633 [10:45<00:00,  5.62it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc_id in tqdm(docs, desc = 'Generating Embeddings'):\n",
    "    combined_text =  docs[doc_id]['text']\n",
    "    docs[doc_id]['embedding'] = get_embedding(combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d279addb-5bef-4f48-9a72-988636c75c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_file_path = './backups/openai_embeddings/doc_embeddings_nfcorpus.pkl'\n",
    "query_file_path = './backups/openai_embeddings/query_embeddings_nfcorpus.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5086b043-2f48-4e4e-b14e-628efeb7b787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to ./backups/openai_embeddings/doc_embeddings_nfcorpus.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(docs_file_path, 'wb') as file:\n",
    "    pickle.dump(docs, file)\n",
    "print(f\"Embeddings saved to {docs_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a561cc29-2113-4b81-bced-ee1723ce64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to ./backups/openai_embeddings/query_embeddings_nfcorpus.pkl\n"
     ]
    }
   ],
   "source": [
    "with open(query_file_path, 'wb') as file:\n",
    "    pickle.dump(queries, file)\n",
    "print(f\"Embeddings saved to {query_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b734048-d856-43bd-9f69-40024b3ef032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document embeddings loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "with open(docs_file_path, 'rb') as file:\n",
    "    loaded_docs = pickle.load(file)\n",
    "print(\"Document embeddings loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "285c5608-caea-43a3-a256-cbefad5888d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(query_file_path, 'rb') as file:\n",
    "    loaded_queries = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99b4cbdb-bb69-48cb-9939-e8385700b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embeddings loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "queries = loaded_queries\n",
    "print(\"Query embeddings loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f52caf1-5194-45fb-9d0c-6cc0b553e623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'embedding'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_docs[\"MED-10\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c97963-defc-4216-a38a-40d50693f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_data = []\n",
    "for doc in loaded_docs:\n",
    "    annoy_data.append((doc, loaded_docs[doc][\"embedding\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81cd874c-b880-4db4-852a-3d220d7857ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vs = FAISS.from_embeddings(\n",
    "    text_embeddings=annoy_data, \n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    distance_strategy=DistanceStrategy.DOT_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1256d907-8925-4bc6-964c-a6e85634ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_vs.save_local(\"./backups/nfcorpus/faiss/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e00668d4-0650-4dd5-934a-2bca0a29f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index from file\n",
    "loaded_faiss_vs = FAISS.load_local(\n",
    "    folder_path=\"./backups/nfcorpus/faiss/\",\n",
    "    embeddings=OpenAIEmbeddings())\n",
    "\n",
    "retriever = loaded_faiss_vs.as_retriever(search_kwargs={'k': 10})\n",
    "\n",
    "# Define the RAG pipeline\n",
    "template = \"\"\"\n",
    "Answer the question or Explain the topic given this additional context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f7a5756-298f-425d-be0e-8816c168a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(_docs):\n",
    "    ls = []\n",
    "    for doc in _docs:\n",
    "        if doc.page_content in docs:\n",
    "            ls.append(docs[doc.page_content][\"text\"][:400])\n",
    "    return ls\n",
    "    # return [docs[int(doc.page_content)][\"body\"] for doc in _docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9b67855-db6b-42a7-8c38-20ca81eaaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ({\"context\": retriever | format_docs, \"question\": RunnablePassthrough()} \n",
    "         | prompt \n",
    "         | llm \n",
    "         | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7307419-5af5-415e-bff9-341f615619db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do Cholesterol Statin Drugs Cause Breast Cancer?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries['PLAIN-2']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ab46da-3217-41c2-aa0f-6518e6935a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: The available evidence on the association between statin use and breast cancer risk is conflicting. Some studies suggest that statins may decrease the risk of breast cancer, while others have found no significant effect. A recent meta-analysis of observational studies did not find any evidence to support the hypothesis that statins have a protective effect against breast cancer. However, there have been some studies that have found an increased risk of breast cancer in long-term users of statins. Further research, including randomized clinical trials, is needed to confirm this association and understand the underlying biological mechanisms. Additionally, there is evidence that low cholesterol levels may be associated with a lower risk of breast cancer, but more research is needed to understand this relationship. Ultimately, the role of cholesterol statin drugs in breast cancer risk remains unclear and more studies are needed to fully understand their impact.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(queries['PLAIN-2']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba9db072-d4e4-4e3a-bff5-735e79954315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking Queries to ChatGPT with RAG: 100%|██████████████████| 323/323 [09:12<00:00,  1.71s/it]\n"
     ]
    }
   ],
   "source": [
    "#### API CALL WARNING #####\n",
    "\n",
    "rag_responses = {}\n",
    "loq = []\n",
    "count  = 0\n",
    "# Run RAG pipeline for every question\n",
    "for query_id in tqdm(rel_set.keys(), desc = 'Asking Queries to ChatGPT with RAG'):\n",
    "    # if count > 100:\n",
    "    #     break\n",
    "    query_text = queries[query_id]['text']\n",
    "    response = chain.invoke(query_text)\n",
    "    rag_responses[query_id] = response\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb7a72be-5f6b-446e-bb7b-63ad8a8d31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG responses saved to ./backups/openai_with_rag_responses_nf_corpus_gpt-3.5-turbo-instruct.pkl\n"
     ]
    }
   ],
   "source": [
    "#### DUMP OVERWRITE WARNING ####\n",
    "\n",
    "rag_responses_file_path = './backups/openai_with_rag_responses_nf_corpus_' + model + '.pkl'\n",
    "with open(rag_responses_file_path, 'wb') as file:\n",
    "    pickle.dump(rag_responses, file)\n",
    "\n",
    "print(f\"RAG responses saved to {rag_responses_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69543307-aca1-4247-94a8-1cd6dd983553",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_with_rag_responses_file_path = './backups/openai_with_rag_responses_nf_corpus_' + model + '.pkl'\n",
    "with open(openai_with_rag_responses_file_path, 'rb') as file:\n",
    "    rag_responses = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "694673f9-44bb-47ff-9fc6-1045afff7035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAnswer: Based on the emerging evidence and conflicting results from previous studies, it is unclear if cholesterol statin drugs directly cause breast cancer. Some studies suggest that statins may decrease the risk of breast cancer, while others have shown no significant association. However, further research is needed to fully understand the potential effects of statins on breast cancer risk. '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Sanity\n",
    "rag_responses['PLAIN-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "86e89275-062c-49f8-ab9b-ad6bd50f4c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BLEU Score: 0.6099\n",
      "Mean ROUGE Score: 0.2024\n"
     ]
    }
   ],
   "source": [
    "# Implement BLEU evaluation function\n",
    "def compute_bleu(references, candidate):\n",
    "    smoothing = SmoothingFunction().method5\n",
    "    return sentence_bleu(references, candidate, smoothing_function=smoothing)\n",
    "\n",
    "# Implement ROUGE evaluation function\n",
    "def compute_rouge(references, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    total_score = 0\n",
    "\n",
    "    # Compute ROUGE for each reference\n",
    "    for reference in references:\n",
    "        scores = scorer.score(reference, candidate)\n",
    "        total_score += scores['rouge1'].fmeasure\n",
    "\n",
    "    # Calculate average score\n",
    "    average_score = total_score / len(references)\n",
    "    return average_score\n",
    "\n",
    "# Evaluate BLEU and ROUGE for each query\n",
    "\n",
    "K = 15 # Number of most relevant docs to consider for scoring performance\n",
    "total_bleu_score = 0.0\n",
    "total_rouge_score = 0.0\n",
    "num_queries = 0\n",
    "\n",
    "for query_id, relevant_docs in rel_set.items():\n",
    "    query_text = queries[query_id]['text']\n",
    "    response = rag_responses[query_id]\n",
    "\n",
    "    # print(query_id, \"\\n\\n\", query_text, \"\\n\\nResponse:\\n\", response, \"\\nTopmost relevant Doc:\\n\", docs[relevant_docs[0]]['text'], \"\\n======\\n\")\n",
    "    \n",
    "    # Evaluate using BLEU\n",
    "    bleu_score = compute_bleu([docs[id]['text'] for id in relevant_docs[:K]], response)\n",
    "    total_bleu_score += bleu_score\n",
    "\n",
    "    # Evaluate using ROUGE\n",
    "    rouge_score = compute_rouge([docs[id]['text'] for id in relevant_docs[:K]], response)\n",
    "    total_rouge_score += rouge_score\n",
    "\n",
    "    num_queries += 1\n",
    "    if num_queries == 101:\n",
    "        break\n",
    "\n",
    "# Calculate mean scores\n",
    "mean_bleu_score = total_bleu_score / num_queries\n",
    "mean_rouge_score = total_rouge_score / num_queries\n",
    "\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22b95aab-2ac2-404f-ba82-55a06e8ae2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# da-vinci\n",
    "# Mean BLEU Score: 0.8224\n",
    "# Mean ROUGE Score: 0.2105\n",
    "\n",
    "# Mean BLEU Score: 0.8377\n",
    "# Mean ROUGE Score: 0.2226\n",
    "\n",
    "# gpt-3.5-turbo-instruct\n",
    "\n",
    "# Mean BLEU Score: 0.7869\n",
    "# Mean ROUGE Score: 0.2407\n",
    "\n",
    "# Mean BLEU Score: 0.7937\n",
    "# Mean ROUGE Score: 0.2425\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
