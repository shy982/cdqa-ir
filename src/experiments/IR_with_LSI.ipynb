{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1006d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e73b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cisi/CISI.ALL\") as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1296f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docs(lines):\n",
    "    title_mode = False\n",
    "    body_mode = False\n",
    "    edge_mode = False\n",
    "    title = \"\"\n",
    "    body = \"\"\n",
    "    idx = None\n",
    "    edge_str = \"\"\n",
    "    edges = []\n",
    "    docs = []\n",
    "    for line in lines:\n",
    "        for c in line:\n",
    "            if line.startswith(\".\"):\n",
    "                if line.startswith(\".I\"):\n",
    "                    for e in edge_str.split(\"\\n\"):\n",
    "                        if \"\\t\" in e:\n",
    "                            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "                    idx = int(line.split()[1])\n",
    "                    edge_str = \"\"\n",
    "                    edge_mode = False\n",
    "                if line.startswith(\".T\"):\n",
    "                    title_mode = True\n",
    "                    body_mode = False\n",
    "                elif line.startswith(\".W\"):\n",
    "                    title_mode = False\n",
    "                    body_mode = True\n",
    "                elif line.startswith(\".X\"):\n",
    "                    docs.append({\"id\": idx, \"title\": title, \"body\": body})\n",
    "                    title = \"\"\n",
    "                    body = \"\"\n",
    "                    title_mode = False\n",
    "                    body_mode = False\n",
    "                    edge_mode = True\n",
    "                else:\n",
    "                    title_mode = False\n",
    "                    body_mode = False \n",
    "                    edge_mode = False\n",
    "            if title_mode:\n",
    "                title += c\n",
    "            elif body_mode:\n",
    "                body += c\n",
    "            elif edge_mode:\n",
    "                edge_str += c\n",
    "    for e in edge_str.split(\"\\n\"):\n",
    "        if \"\\t\" in e:\n",
    "            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "    return [x for x in docs if x[\"title\"]], sorted(list(set(edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ae9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, edges = extract_docs(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "012aace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6426aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}\n",
    "\n",
    "idx = None\n",
    "with open(\"../data/cisi/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = \"\"\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx] += \" \"+line\n",
    "        if idx:\n",
    "            queries[idx] = tokenizer(queries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d0fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(docs):\n",
    "    sentences_clean = []\n",
    "    for sentence in docs:\n",
    "        lookup_table = sentence.maketrans('', '', string.punctuation)\n",
    "        clean_text = sentence.translate(lookup_table)\n",
    "        word_list = word_tokenize(clean_text)\n",
    "        word_list = [w for w in word_list if not w in stop_words and len(w) > 2]\n",
    "        word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "        clean_text = ' '.join(word_list)\n",
    "        sentences_clean.append(clean_text)\n",
    "    return sentences_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff851064",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_body = [doc['body'] for doc in docs]\n",
    "clean_documents = clean_text(docs_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5e6f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}\n",
    "\n",
    "idx = None\n",
    "with open(\"../data/cisi/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = \"\"\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx] += \" \"+line\n",
    "queries = [queries[idx] for idx in range(1,len(queries)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee08ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_queries = clean_text(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91acea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(clean_documents+clean_queries)\n",
    "documents_vectors = vectorizer.transform(clean_documents)\n",
    "queries_vectors = vectorizer.transform(clean_queries)\n",
    "num_topics = 100\n",
    "svd = TruncatedSVD(n_components=num_topics)\n",
    "documents_reduced = svd.fit_transform(documents_vectors)\n",
    "queries_reduced = svd.fit_transform(queries_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d40f92c-1fde-49de-912e-8774937c4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./backups/lsi/documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents_reduced, f)\n",
    "\n",
    "with open(\"./backups/lsi/queries.pkl\", \"wb\") as f:\n",
    "    pickle.dump(queries_reduced, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d25a6d-9653-49b6-a93e-be87675b5993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1460, 100), (112, 100))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_reduced.shape, queries_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d27f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 112it [00:01, 74.68it/s]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Calculate cosine similarity for each query-document pair\n",
    "similarity_scores = {}\n",
    "for query_id, query in tqdm(enumerate(queries_reduced), desc = 'Computing similarity scores'):\n",
    "    scores = []\n",
    "    for doc_id, doc in enumerate(documents_reduced):\n",
    "        sim_score = cosine_similarity(query, doc)\n",
    "        scores.append((doc_id, sim_score))\n",
    "    similarity_scores[query_id] = sorted(scores, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f17d12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = 0\n",
    "    for doc_id in ranked_docs[:k]:\n",
    "        if doc_id in relevant_docs:\n",
    "            retrieved_relevant += 1\n",
    "    return retrieved_relevant / k\n",
    "\n",
    "def recall_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = sum(1 for doc_id in ranked_docs[:k] if doc_id in relevant_docs)\n",
    "    return retrieved_relevant / len(relevant_docs) if relevant_docs else 0\n",
    "\n",
    "def dcg_at_k(scores, k=10):\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores[:k]))\n",
    "\n",
    "def ndcg_at_k(ranked_docs, relevant_docs, k=5):\n",
    "    ideal_scores = [1 if doc_id in relevant_docs else 0 for doc_id in ranked_docs]\n",
    "    actual_scores = [1 if doc_id in relevant_docs else 0 for doc_id in ranked_docs[:k]]\n",
    "    idcg = dcg_at_k(ideal_scores, k)\n",
    "    dcg = dcg_at_k(actual_scores, k)\n",
    "    return dcg / idcg if idcg > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "419f549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cisi/CISI.REL\") as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "    ground_truth = [[]]*len(lines)\n",
    "    for line in lines:\n",
    "        clean_line = line.strip().replace('\\t',' ').split()\n",
    "        query, doc = [int(num.replace(' ','')) for num in clean_line[:2]]\n",
    "        ground_truth[query].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5758cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0]*len(similarity_scores)\n",
    "for idx, scores in similarity_scores.items():\n",
    "    scores_flattened = [doc for doc,score in scores]\n",
    "    predictions[idx] = scores_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1be5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_precision_at_k = np.mean([precision_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])\n",
    "mean_recall_at_k = np.mean([recall_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])\n",
    "mean_ndcg_at_k = np.mean([ndcg_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa6bd63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8267857142857143, 0.0026550600972566284, 1.0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision_at_k, mean_recall_at_k, mean_ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "414b9976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8482142857142857"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sps = np.mean([precision_at_k(preds,label,k=1) for preds,label in zip(predictions,ground_truth)])\n",
    "sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05815140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
