{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c1006d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e73b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cisi/CISI.ALL\") as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1296f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docs(lines):\n",
    "    title_mode = False\n",
    "    body_mode = False\n",
    "    edge_mode = False\n",
    "    title = \"\"\n",
    "    body = \"\"\n",
    "    idx = None\n",
    "    edge_str = \"\"\n",
    "    edges = []\n",
    "    docs = []\n",
    "    for line in lines:\n",
    "        for c in line:\n",
    "            if line.startswith(\".\"):\n",
    "                if line.startswith(\".I\"):\n",
    "                    for e in edge_str.split(\"\\n\"):\n",
    "                        if \"\\t\" in e:\n",
    "                            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "                    idx = int(line.split()[1])\n",
    "                    edge_str = \"\"\n",
    "                    edge_mode = False\n",
    "                if line.startswith(\".T\"):\n",
    "                    title_mode = True\n",
    "                    body_mode = False\n",
    "                elif line.startswith(\".W\"):\n",
    "                    title_mode = False\n",
    "                    body_mode = True\n",
    "                elif line.startswith(\".X\"):\n",
    "                    docs.append({\"id\": idx, \"title\": title, \"body\": body})\n",
    "                    title = \"\"\n",
    "                    body = \"\"\n",
    "                    title_mode = False\n",
    "                    body_mode = False\n",
    "                    edge_mode = True\n",
    "                else:\n",
    "                    title_mode = False\n",
    "                    body_mode = False \n",
    "                    edge_mode = False\n",
    "            if title_mode:\n",
    "                title += c\n",
    "            elif body_mode:\n",
    "                body += c\n",
    "            elif edge_mode:\n",
    "                edge_str += c\n",
    "    for e in edge_str.split(\"\\n\"):\n",
    "        if \"\\t\" in e:\n",
    "            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "    return [x for x in docs if x[\"title\"]], sorted(list(set(edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae9260",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, edges = extract_docs(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012aace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    return word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6426aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}\n",
    "\n",
    "idx = None\n",
    "with open(\"../data/cisi/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = \"\"\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx] += \" \"+line\n",
    "        if idx:\n",
    "            queries[idx] = tokenizer(queries[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(docs):\n",
    "    sentences_clean = []\n",
    "    for sentence in docs:\n",
    "        lookup_table = sentence.maketrans('', '', string.punctuation)\n",
    "        clean_text = sentence.translate(lookup_table)\n",
    "        word_list = word_tokenize(clean_text)\n",
    "        word_list = [w for w in word_list if not w in stop_words and len(w) > 2]\n",
    "        word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "        clean_text = ' '.join(word_list)\n",
    "        sentences_clean.append(clean_text)\n",
    "    return sentences_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff851064",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_body = [doc['body'] for doc in docs]\n",
    "clean_documents = clean_text(docs_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df00a78-94cd-41c1-b12b-a4e07b09f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./backups/openai_embeddings/doc_embeddings_nfcorpus.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cd75238-6f49-417c-837b-fd739b787617",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = list(documents.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f389e103-697d-4273-9668-f50e05a07f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_documents = [documents[doc][\"text\"] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d43904c5-31ae-40f2-a08f-0c7bdd327a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./backups/openai_embeddings/query_embeddings_nfcorpus.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a2004b-4ad3-4b5b-9bed-fd8bbdf65613",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_ids = list(queries.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b864bf6a-f903-47e7-adba-f40ea5e00c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_queries = [queries[q][\"text\"] for q in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c00c90-73ad-4b28-854a-5db35a3e7196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3633, 323)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_documents), len(clean_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69d6839b-12c4-4a5f-b6a6-611e2617cfdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MED-10',\n",
       " 'Recent studies have suggested that statins, an established drug group in the prevention of cardiovascular mortality, could delay or prevent breast cancer recurrence but the effect on disease-specific mortality remains unclear. We evaluated risk of breast cancer death among statin users in a population-based cohort of breast cancer patients. The study cohort included all newly diagnosed breast cancer patients in Finland during 1995–2003 (31,236 cases), identified from the Finnish Cancer Registry. Information on statin use before and after the diagnosis was obtained from a national prescription database. We used the Cox proportional hazards regression method to estimate mortality among statin users with statin use as time-dependent variable. A total of 4,151 participants had used statins. During the median follow-up of 3.25 years after the diagnosis (range 0.08–9.0 years) 6,011 participants died, of which 3,619 (60.2%) was due to breast cancer. After adjustment for age, tumor characteristics, and treatment selection, both post-diagnostic and pre-diagnostic statin use were associated with lowered risk of breast cancer death (HR 0.46, 95% CI 0.38–0.55 and HR 0.54, 95% CI 0.44–0.67, respectively). The risk decrease by post-diagnostic statin use was likely affected by healthy adherer bias; that is, the greater likelihood of dying cancer patients to discontinue statin use as the association was not clearly dose-dependent and observed already at low-dose/short-term use. The dose- and time-dependence of the survival benefit among pre-diagnostic statin users suggests a possible causal effect that should be evaluated further in a clinical trial testing statins’ effect on survival in breast cancer patients.',\n",
       " 'PLAIN-2',\n",
       " 'Do Cholesterol Statin Drugs Cause Breast Cancer?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_ids[0], clean_documents[0], query_ids[0], clean_queries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e6f6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}\n",
    "\n",
    "idx = None\n",
    "with open(\"../data/cisi/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = \"\"\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx] += \" \"+line\n",
    "queries = [queries[idx] for idx in range(1,len(queries)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee08ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_queries = clean_text(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91acea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(clean_documents+clean_queries)\n",
    "documents_vectors = vectorizer.transform(clean_documents)\n",
    "queries_vectors = vectorizer.transform(clean_queries)\n",
    "num_topics = 100\n",
    "svd = TruncatedSVD(n_components=num_topics)\n",
    "documents_reduced = svd.fit_transform(documents_vectors)\n",
    "queries_reduced = svd.fit_transform(queries_vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b5b9dac-6872-4027-a268-3925692ea621",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_reduced_dict = {id: vector for id, vector in zip(document_ids, documents_reduced)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1a668d-b198-45ae-a111-49fcaab9f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_reduced_dict = {id: vector for id, vector in zip(query_ids, queries_reduced)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d40f92c-1fde-49de-912e-8774937c4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./backups/lsi/nf_corpus/documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(documents_reduced_dict, f)\n",
    "\n",
    "with open(\"./backups/lsi/nf_corpus/queries.pkl\", \"wb\") as f:\n",
    "    pickle.dump(queries_reduced_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d27f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 1406it [00:09, 154.94it/s]\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Calculate cosine similarity for each query-document pair\n",
    "similarity_scores = {}\n",
    "for query_id, query in tqdm(enumerate(queries_reduced), desc = 'Computing similarity scores'):\n",
    "    scores = []\n",
    "    for doc_id, doc in enumerate(documents_reduced):\n",
    "        sim_score = cosine_similarity(query, doc)\n",
    "        scores.append((doc_id, sim_score))\n",
    "    similarity_scores[query_id] = sorted(scores, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d12c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = 0\n",
    "    for doc_id in ranked_docs[:k]:\n",
    "        if doc_id in relevant_docs:\n",
    "            retrieved_relevant += 1\n",
    "    return retrieved_relevant / k\n",
    "\n",
    "def recall_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = sum(1 for doc_id in ranked_docs[:k] if doc_id in relevant_docs)\n",
    "    return retrieved_relevant / len(relevant_docs) if relevant_docs else 0\n",
    "\n",
    "def dcg_at_k(scores, k=10):\n",
    "    return sum(score / np.log2(idx + 2) for idx, score in enumerate(scores[:k]))\n",
    "\n",
    "def ndcg_at_k(ranked_docs, relevant_docs, k=5):\n",
    "    ideal_scores = [1 if doc_id in relevant_docs else 0 for doc_id in ranked_docs]\n",
    "    actual_scores = [1 if doc_id in relevant_docs else 0 for doc_id in ranked_docs[:k]]\n",
    "    idcg = dcg_at_k(ideal_scores, k)\n",
    "    dcg = dcg_at_k(actual_scores, k)\n",
    "    return dcg / idcg if idcg > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/cisi/CISI.REL\") as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "    ground_truth = [[]]*len(lines)\n",
    "    for line in lines:\n",
    "        clean_line = line.strip().replace('\\t',' ').split()\n",
    "        query, doc = [int(num.replace(' ','')) for num in clean_line[:2]]\n",
    "        ground_truth[query].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [0]*len(similarity_scores)\n",
    "for idx, scores in similarity_scores.items():\n",
    "    scores_flattened = [doc for doc,score in scores]\n",
    "    predictions[idx] = scores_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1be5a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_precision_at_k = np.mean([precision_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])\n",
    "mean_recall_at_k = np.mean([recall_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])\n",
    "mean_ndcg_at_k = np.mean([ndcg_at_k(preds,label) for preds,label in zip(predictions,ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_precision_at_k, mean_recall_at_k, mean_ndcg_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = np.mean([precision_at_k(preds,label,k=1) for preds,label in zip(predictions,ground_truth)])\n",
    "sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05815140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
