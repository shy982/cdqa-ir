{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0505fcde-d219-4d26-8b68-7ae4d91c7f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from rouge_score import rouge_scorer\n",
    "from operator import itemgetter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "import numpy as np\n",
    "import time\n",
    "from langchain.vectorstores import Annoy, FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "843b1938-ea5d-4235-8885-6a2021d3ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf03c092-a470-4632-ac34-8d094a287cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load CISI documents & queries\n",
    "\n",
    "with open(\"./cisi/dataset/documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "print(\"Documents loaded succesfully.\")\n",
    "\n",
    "with open(\"./cisi/dataset/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)\n",
    "\n",
    "print(\"Queries loaded succesfully.\")\n",
    "\n",
    "# Load CISI ground truth\n",
    "with open(\"./cisi/dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "\n",
    "print(\"Ground truth loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9262b9e3-f004-4c59-9dad-c7558bcc3ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42292239-268f-4533-a56d-8cce95947c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = list(ground_truth.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2436d55b-96b8-4340-aa23-f81031b4adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSI Predictions loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load LSI predictions\n",
    "with open(\"./cisi/ir_techniques/exact_search/index.pkl\", \"rb\") as f:\n",
    "    lsi_predictions = pickle.load(f)\n",
    "\n",
    "print(\"LSI Predictions loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "223fc22c-90e7-4c77-aeb2-86225e99676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsi_predictions = list(lsi_predictions.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8226b4-d078-41e0-8381-7c976f160a9e",
   "metadata": {},
   "source": [
    "## Information Retrieval - Experimental Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ec5583-6d4f-4777-993f-7fc09d1543ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5d321df-b758-49d5-953e-dfdadc03dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = 0\n",
    "    for doc_id in ranked_docs[:k]:\n",
    "        if doc_id in relevant_docs:\n",
    "            retrieved_relevant += 1\n",
    "    return retrieved_relevant / k\n",
    "\n",
    "def recall_at_k(ranked_docs, relevant_docs, k=10):\n",
    "    retrieved_relevant = sum(1 for doc_id in ranked_docs[:k] if doc_id in relevant_docs)\n",
    "    return retrieved_relevant / len(relevant_docs) if relevant_docs else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "553e5e54-9753-4e25-a11a-fa75438ff5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_precision_at_k = np.mean([precision_at_k(preds,label) for preds,label in zip(lsi_predictions,ground_truth)])\n",
    "mean_recall_at_k = np.mean([recall_at_k(preds,label) for preds,label in zip(lsi_predictions,ground_truth)])\n",
    "mean_sps = np.mean([precision_at_k(preds,label,1) for preds,label in zip(lsi_predictions,ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8c9df30-3616-435d-9f29-3f201c05922a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.014473684210526317, 0.005305212696304631, 0.013157894736842105)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision_at_k, mean_recall_at_k, mean_sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975226f-5285-4516-b1ee-f7c20d6e5a6c",
   "metadata": {},
   "source": [
    "#### OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fe31135-30c8-473a-b0f9-5414528d17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cd7db9d0-fac7-4151-b3f8-0e6514f653e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI embeddings\n",
    "with open(\"./cisi/embeddings/text-embedding-ada-002-v2/documents.pkl\", \"rb\") as f:\n",
    "    documents_openai = pickle.load(f)\n",
    "\n",
    "with open(\"./cisi/embeddings/text-embedding-ada-002-v2/queries.pkl\", \"rb\") as f:\n",
    "    queries_openai = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22c0dce2-445b-41de-b6b4-f7a1f4bfae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63f4937b-57c4-4c5f-a12e-bcff0605ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 100%|████████████| 112/112 [00:28<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean execution time for all queries: 252.24 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for each query-document pair\n",
    "similarity_scores = {}\n",
    "execution_times = [] \n",
    "for query_id, query in tqdm(queries_openai.items(), desc = 'Computing similarity scores'):\n",
    "    query_embedding = query['embedding']\n",
    "    scores = []\n",
    "    start_time = time.time()\n",
    "    for doc in documents_openai:\n",
    "        doc_embedding = documents_openai[doc]['embedding']\n",
    "        sim_score = cosine_similarity(query_embedding, doc_embedding)\n",
    "        scores.append((doc, sim_score))\n",
    "    \n",
    "    end_time = time.time()  # Record end time\n",
    "    execution_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "    execution_times.append(execution_time)\n",
    "    similarity_scores[query_id] = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "mean_execution_time = sum(execution_times) / len(execution_times)\n",
    "print(f\"Mean execution time for all queries: {mean_execution_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e178e0a-65cc-4f1a-9c8e-0eb230b908d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_predictions = {}\n",
    "for query_id, scores in similarity_scores.items():\n",
    "    # Flatten the scores to get only document IDs\n",
    "    scores_flattened = [doc_id for doc_id, _ in scores]\n",
    "    openai_predictions[query_id] = scores_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f91ee73-b7e9-4ae9-95fa-8d0d00bfe2bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_predictions = list(openai_predictions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afeafb72-0cad-4d1b-8742-3170c3aa6ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_precision_at_k = np.mean([precision_at_k(preds,label) for preds,label in zip(openai_predictions,ground_truth)])\n",
    "mean_recall_at_k = np.mean([recall_at_k(preds,label) for preds,label in zip(openai_predictions,ground_truth)])\n",
    "mean_sps = np.mean([precision_at_k(preds,label,1) for preds,label in zip(openai_predictions,ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3882d831-6782-4391-8091-ecfa6183a058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1828947368421053, 0.047888229233635914, 0.19736842105263158)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_precision_at_k, mean_recall_at_k, mean_sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b7bc6-b1e8-4f89-9d00-2765ce7869cb",
   "metadata": {},
   "source": [
    "#### VectorDB - FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eda8f1eb-357b-498a-8c9d-61e0fb707b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load index from file\n",
    "loaded_faiss_vs = FAISS.load_local(\n",
    "    folder_path=\"./cisi/ir_techniques/faiss/\",\n",
    "    embeddings=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f9461183-f2a1-4bf9-a206-f2a1f3d179fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 100%|███████████| 112/112 [00:00<00:00, 646.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean execution time for all queries: 1.40 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for each query-document pair\n",
    "faiss_similarity_scores = {}\n",
    "execution_times = [] \n",
    "for query_id, query in tqdm(queries_openai.items(), desc=\"Computing similarity scores\"):\n",
    "    start_time = time.time()\n",
    "    scores = loaded_faiss_vs.similarity_search_with_score_by_vector(query[\"embedding\"], k=100)\n",
    "    end_time = time.time()  # Record end time\n",
    "    execution_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "    new_scores = []\n",
    "    for score in scores:\n",
    "        new_scores.append((int(score[0].page_content), 1 - score[1]))\n",
    "    faiss_similarity_scores[query_id] = sorted(new_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "mean_execution_time = sum(execution_times) / len(execution_times)\n",
    "print(f\"Mean execution time for all queries: {mean_execution_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e764340a-9cd4-44a6-aacc-ef3b90c67e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_predictions = [0]*(len(faiss_similarity_scores)+1)\n",
    "for idx, scores in faiss_similarity_scores.items():\n",
    "    scores_flattened = [doc for doc, score in scores]\n",
    "    faiss_predictions[idx] = scores_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "85db28cb-ba9c-4439-8023-b62031545b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_mean_precision_at_k = np.mean(\n",
    "    [precision_at_k(preds, label) for preds, label in zip(faiss_predictions[1:], ground_truth)])\n",
    "faiss_mean_recall_at_k = np.mean(\n",
    "    [recall_at_k(preds, label) for preds, label in zip(faiss_predictions[1:], ground_truth)])\n",
    "faiss_mean_sps = np.mean(\n",
    "    [precision_at_k(preds, label, 1) for preds, label in zip(faiss_predictions[1:], ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ac06dabc-bf31-4347-a012-093acd69f6aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1828947368421053, 0.047888229233635914, 0.19736842105263158)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_mean_precision_at_k, faiss_mean_recall_at_k, faiss_mean_sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054cb5b7-f4b4-47b8-b12e-20a9f6301adf",
   "metadata": {},
   "source": [
    "#### VectorDB - ANNOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8f03d10-26c5-4d7c-a143-f2a0b23ee192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ANNOY index from file\n",
    "loaded_annoy_vs = Annoy.load_local(\n",
    "    folder_path=\"./cisi/ir_techniques/annoy/\", \n",
    "    embeddings=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2656a8c9-44e6-4a1b-bea2-b62a3687de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing similarity scores: 100%|███████████| 112/112 [00:00<00:00, 323.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean execution time for all queries: 3.03 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity for each query-document pair\n",
    "annoy_similarity_scores = {}\n",
    "execution_times = [] \n",
    "for query_id, query in tqdm(queries_openai.items(), desc=\"Computing similarity scores\"):\n",
    "    start_time = time.time()\n",
    "    scores = loaded_annoy_vs.similarity_search_with_score_by_vector(query[\"embedding\"], k=100)\n",
    "    end_time = time.time()  # Record end time\n",
    "    execution_time = (end_time - start_time) * 1000  # Convert to milliseconds\n",
    "    execution_times.append(execution_time)\n",
    "\n",
    "    new_scores = []\n",
    "    for score in scores:\n",
    "        new_scores.append((int(score[0].page_content), score[1]))\n",
    "    annoy_similarity_scores[query_id] = sorted(new_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "mean_execution_time = sum(execution_times) / len(execution_times)\n",
    "print(f\"Mean execution time for all queries: {mean_execution_time:.2f} ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a5d1eb46-8c94-429c-8e7a-91c5bba014ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_predictions = [0]*(len(annoy_similarity_scores)+1)\n",
    "for idx, scores in annoy_similarity_scores.items():\n",
    "    scores_flattened = [doc for doc, score in scores]\n",
    "    annoy_predictions[idx] = scores_flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd87644-0a31-423b-bb27-ccfcdfc87db4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "355ef12c-dfbf-40be-9fa4-008586a44b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_mean_precision_at_k = np.mean(\n",
    "    [precision_at_k(preds, label) for preds, label in zip(annoy_predictions[1:], ground_truth)])\n",
    "annoy_mean_recall_at_k = np.mean(\n",
    "    [recall_at_k(preds, label) for preds, label in zip(annoy_predictions[1:], ground_truth)])\n",
    "annoy_mean_sps = np.mean(\n",
    "    [precision_at_k(preds, label, 1) for preds, label in zip(annoy_predictions[1:], ground_truth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1fa4ed20-7712-4456-994c-ec78d870c3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1828947368421053, 0.047888229233635914, 0.19736842105263158)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annoy_mean_precision_at_k, annoy_mean_recall_at_k, annoy_mean_sps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e7d73-2a86-4c2d-854d-d49fe5c57bef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3516ac6a-c46f-4073-b3cb-e92b3b1decbb",
   "metadata": {},
   "source": [
    "## RAG Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af72d5ad-6cbe-45a9-97f6-aea39961f2cc",
   "metadata": {},
   "source": [
    "### CISI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7cfe7886-f712-4eab-984b-4e1da2821132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load CISI ground truth\n",
    "with open(\"./cisi/dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "\n",
    "print(\"Ground truth loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1e31be3a-56cd-4abb-8e69-d1b32aa910e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da-vinci-0.0.3 responses with & without RAG loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load davinci-0.0.3 responses\n",
    "with open(\"./cisi/responses/da-vinci-0.0.3/llm_w_rag_faiss.pkl\", \"rb\") as f:\n",
    "    da_vinci_llm_w_rag = pickle.load(f)\n",
    "\n",
    "with open(\"./cisi/responses/da-vinci-0.0.3/llm_wo_rag.pkl\", \"rb\") as f:\n",
    "    da_vinci_llm_wo_rag = pickle.load(f)\n",
    "\n",
    "print(\"da-vinci-0.0.3 responses with & without RAG loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e8c8a233-4f29-4dd7-bb70-44ddc27879a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load gpt-3.5-turbo-instruct responses\n",
    "with open(\"./cisi/responses/gpt-3.5-turbo-instruct/llm_w_rag_faiss.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_faiss = pickle.load(f)\n",
    "\n",
    "with open(\"./cisi/responses/gpt-3.5-turbo-instruct/llm_w_rag_exact_search.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_exact_search = pickle.load(f)\n",
    "    \n",
    "with open(\"./cisi/responses/gpt-3.5-turbo-instruct/llm_wo_rag.pkl\", \"rb\") as f:\n",
    "    gpt_llm_wo_rag = pickle.load(f)\n",
    "\n",
    "print(\"gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d3723fa-0d3a-441b-8a28-352927f0166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama-7b responses with & without RAG loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load llama-7b responses\n",
    "with open(\"./cisi/responses/llama-7b/llm_w_rag_faiss.pkl\", \"rb\") as f:\n",
    "    llama_7b_llm_w_rag = pickle.load(f)\n",
    "\n",
    "with open(\"./cisi/responses/llama-7b/llm_wo_rag.pkl\", \"rb\") as f:\n",
    "    llama_7b_llm_wo_rag = pickle.load(f)\n",
    "\n",
    "print(\"llama-7b responses with & without RAG loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0865f91f-7f09-4988-a2f7-e0608bc09388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement BLEU evaluation function\n",
    "def compute_bleu(references, candidate):\n",
    "    smoothing = SmoothingFunction().method5\n",
    "    return sentence_bleu(references, candidate, smoothing_function=smoothing)\n",
    "\n",
    "# Implement ROUGE evaluation function\n",
    "def compute_rouge(references, candidate):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
    "    total_score = 0\n",
    "\n",
    "    # Compute ROUGE for each reference\n",
    "    for reference in references:\n",
    "        scores = scorer.score(reference, candidate)\n",
    "        total_score += scores['rouge1'].fmeasure\n",
    "\n",
    "    # Calculate average score\n",
    "    if references:\n",
    "        average_score = total_score / len(references)\n",
    "    else:\n",
    "        average_score = 0\n",
    "    return average_score\n",
    "\n",
    "\n",
    "\n",
    "def compute_mean_bleu_score(rag_responses, relevant_docs, K = 10):\n",
    "    total_bleu_score = 0.0\n",
    "    num_queries = 0\n",
    "    for query_id, relevant_docs in ground_truth.items():\n",
    "        query_text = queries[query_id]['text']\n",
    "        response = rag_responses[query_id]['response']\n",
    "        if relevant_docs:\n",
    "            bleu_score = compute_bleu([documents[id]['text'] for id in relevant_docs[:K]], response)\n",
    "        else:\n",
    "            bleu_score = 0\n",
    "        total_bleu_score += bleu_score\n",
    "        num_queries += 1\n",
    "        if num_queries == 101:\n",
    "            break\n",
    "    mean_bleu_score = total_bleu_score / num_queries\n",
    "    return mean_bleu_score\n",
    "\n",
    "def compute_mean_rouge_score(rag_responses, relevant_docs, K = 10):\n",
    "    total_rouge_score = 0.0\n",
    "    num_queries = 0\n",
    "    for query_id, relevant_docs in ground_truth.items():\n",
    "        query_text = queries[query_id]['text']\n",
    "        response = rag_responses[query_id]['response']\n",
    "        rouge_score = compute_rouge([documents[id]['text'] for id in relevant_docs[:K]], response)\n",
    "        total_rouge_score += rouge_score\n",
    "        num_queries += 1\n",
    "        if num_queries == 101:\n",
    "            break\n",
    "    mean_rouge_score = total_rouge_score / num_queries\n",
    "    return mean_rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeffdb9-5cec-4d63-aa61-a46b56c23d24",
   "metadata": {},
   "source": [
    "#### da-vinci-0.0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "63eef9b0-2d50-438e-b9c5-1f56e473d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for davinci with without RAG\n",
    "\n",
    "mean_bleu_score_davinci_wo_rag = compute_mean_bleu_score(da_vinci_llm_wo_rag, ground_truth)\n",
    "mean_bleu_score_davinci_w_rag = compute_mean_bleu_score(da_vinci_llm_w_rag, ground_truth)\n",
    "mean_rouge_score_davinci_wo_rag = compute_mean_rouge_score(da_vinci_llm_wo_rag, ground_truth)\n",
    "mean_rouge_score_davinci_w_rag = compute_mean_rouge_score(da_vinci_llm_w_rag, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "27b721f5-5996-455d-a811-824e9779e11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without RAG\n",
      "============\n",
      "Mean BLEU Score: 0.6076\n",
      "Mean ROUGE Score: 0.1759\n",
      "With RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.8368\n",
      "Mean ROUGE Score: 0.2370\n"
     ]
    }
   ],
   "source": [
    "print(\"Without RAG\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_davinci_wo_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_davinci_wo_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_davinci_w_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_davinci_w_rag:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8c761-5fa4-400e-9070-2b3b6d5c901c",
   "metadata": {},
   "source": [
    "#### gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cfd15edd-17de-40b6-9eab-505b07082b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for gpt without RAG\n",
    "\n",
    "mean_bleu_score_gpt_wo_rag = compute_mean_bleu_score(gpt_llm_wo_rag, ground_truth)\n",
    "mean_rouge_score_gpt_wo_rag = compute_mean_rouge_score(gpt_llm_wo_rag, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1303ad0-bc58-4d22-89cd-10d038c3d2e5",
   "metadata": {},
   "source": [
    "##### NLA Method (LSI + Truncated SVD) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ee4f796b-d04a-47fe-a739-4cbcb00af20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_lsi_rag = compute_mean_bleu_score(gpt_llm_w_rag_exact_search, ground_truth)\n",
    "mean_rouge_score_gpt_w_lsi_rag = compute_mean_rouge_score(gpt_llm_w_rag_exact_search, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831fe6c3-1062-4767-baaa-109de49204e0",
   "metadata": {},
   "source": [
    "##### SOTA Method (VectorDB i.e. FAISS) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c0328dd5-8145-4bf3-be88-aca567bc93ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_faiss_rag = compute_mean_bleu_score(gpt_llm_w_rag_faiss, ground_truth)\n",
    "mean_rouge_score_gpt_w_faiss_rag = compute_mean_rouge_score(gpt_llm_w_rag_faiss, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "98e8c00e-6e24-4738-a842-20136b61ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.8429\n",
      "Mean ROUGE Score: 0.2724\n",
      "\n",
      "With LSI RAG\n",
      "============\n",
      "Mean BLEU Score: 0.6967\n",
      "Mean ROUGE Score: 0.2222\n",
      "\n",
      "With VectorDB RAG\n",
      "============\n",
      "Mean BLEU Score: 0.8273\n",
      "Mean ROUGE Score: 0.2675\n"
     ]
    }
   ],
   "source": [
    "print(\"Without RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_wo_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_wo_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith LSI RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_lsi_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_lsi_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith VectorDB RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_faiss_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_faiss_rag:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a53ac-d6ce-46e3-950a-b6e817755cfc",
   "metadata": {},
   "source": [
    "#### llama-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7b926e2c-4bc3-4e8d-a96d-193608d84d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute for llama-7b with without RAG\n",
    "\n",
    "mean_bleu_score_llama_7b_wo_rag = compute_mean_bleu_score(llama_7b_llm_wo_rag, ground_truth)\n",
    "mean_bleu_score_llama_7b_w_rag = compute_mean_bleu_score(llama_7b_llm_w_rag, ground_truth)\n",
    "mean_rouge_score_llama_7b_wo_rag = compute_mean_rouge_score(llama_7b_llm_wo_rag, ground_truth)\n",
    "mean_rouge_score_llama_7b_w_rag = compute_mean_rouge_score(llama_7b_llm_w_rag, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5039930d-d137-4b30-a8b6-e38de3b4698c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without RAG\n",
      "============\n",
      "Mean BLEU Score: 0.6943\n",
      "Mean ROUGE Score: 0.2218\n",
      "\n",
      "With RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.8008\n",
      "Mean ROUGE Score: 0.2613\n"
     ]
    }
   ],
   "source": [
    "print(\"Without RAG\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_llama_7b_wo_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_llama_7b_wo_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_llama_7b_w_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_llama_7b_w_rag:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad02390-192e-4b07-a2f0-71c2810229df",
   "metadata": {},
   "source": [
    "### arguAna Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e114891e-89bd-4a0f-9a67-11b0933b1052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded succesfully.\n",
      "Queries loaded succesfully.\n",
      "Ground truth loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load arguAna documents & queries\n",
    "\n",
    "with open(\"./arguana/dataset/documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "print(\"Documents loaded succesfully.\")\n",
    "\n",
    "with open(\"./arguana/dataset/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)\n",
    "\n",
    "print(\"Queries loaded succesfully.\")\n",
    "\n",
    "# Load CISI ground truth\n",
    "with open(\"./arguana/dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "\n",
    "print(\"Ground truth loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "af726f54-6518-4f0b-9ada-0ceadca912c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load gpt-3.5-turbo-instruct responses\n",
    "with open(\"./arguana/responses/gpt-3.5-turbo-instruct/llm_w_rag_faiss.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_faiss = pickle.load(f)\n",
    "\n",
    "with open(\"./arguana/responses/gpt-3.5-turbo-instruct/llm_w_rag_exact_search.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_exact_search = pickle.load(f)\n",
    "    \n",
    "print(\"gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a5fddd-2f4d-4c31-9cba-aa13dea51685",
   "metadata": {},
   "source": [
    "#### gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf4cdc-482a-46b2-b31e-6d20b3889fc9",
   "metadata": {},
   "source": [
    "##### NLA Method (LSI + Truncated SVD) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "015f74fb-a594-4b08-8837-9ea603f2f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_lsi_rag = compute_mean_bleu_score(gpt_llm_w_rag_exact_search, ground_truth)\n",
    "mean_rouge_score_gpt_w_lsi_rag = compute_mean_rouge_score(gpt_llm_w_rag_exact_search, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bd6048-a429-4b61-9fb4-97c80604c7f5",
   "metadata": {},
   "source": [
    "##### SOTA Method (VectorDB i.e. FAISS) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ba7ee9ca-2d1e-441c-86fc-7765046f74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_faiss_rag = compute_mean_bleu_score(gpt_llm_w_rag_faiss, ground_truth)\n",
    "mean_rouge_score_gpt_w_faiss_rag = compute_mean_rouge_score(gpt_llm_w_rag_faiss, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d052a070-70eb-47e1-ab7b-5ccabe55d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With LSI RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.2721\n",
      "Mean ROUGE Score: 0.2289\n",
      "\n",
      "With VectorDB RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.2906\n",
      "Mean ROUGE Score: 0.2544\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWith LSI RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_lsi_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_lsi_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith VectorDB RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_faiss_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_faiss_rag:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee02ef-641c-46ff-9e5e-9841123726bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdff7fbe-0522-4591-a135-5c08f9791ae2",
   "metadata": {},
   "source": [
    "### NFCorpus Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "22702608-4448-41ff-b41d-371fec0383e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents loaded succesfully.\n",
      "Queries loaded succesfully.\n",
      "Ground truth loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load arguAna documents & queries\n",
    "\n",
    "with open(\"./nfcorpus/dataset/documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)\n",
    "\n",
    "print(\"Documents loaded succesfully.\")\n",
    "\n",
    "with open(\"./nfcorpus/dataset/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)\n",
    "\n",
    "print(\"Queries loaded succesfully.\")\n",
    "\n",
    "# Load CISI ground truth\n",
    "with open(\"./nfcorpus/dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    ground_truth = pickle.load(f)\n",
    "\n",
    "print(\"Ground truth loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "a28c9300-afb6-4014-a532-3f56e3518fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\n"
     ]
    }
   ],
   "source": [
    "# Load gpt-3.5-turbo-instruct responses\n",
    "with open(\"./nfcorpus/responses/gpt-3.5-turbo-instruct/llm_w_rag_faiss.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_faiss = pickle.load(f)\n",
    "\n",
    "with open(\"./nfcorpus/responses/gpt-3.5-turbo-instruct/llm_w_rag_exact_search.pkl\", \"rb\") as f:\n",
    "    gpt_llm_w_rag_exact_search = pickle.load(f)\n",
    "    \n",
    "print(\"gpt-3.5-turbo-instruct responses with & without RAG loaded succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984998f-71bf-45c5-9700-8f2c85099966",
   "metadata": {},
   "source": [
    "#### gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f29c8a-ef97-40ff-aa1f-f976457fc72a",
   "metadata": {},
   "source": [
    "##### NLA Method (LSI + Truncated SVD) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97bde1f-47e9-4e00-b6d3-70a8cf3c23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_lsi_rag = compute_mean_bleu_score(gpt_llm_w_rag_exact_search, ground_truth)\n",
    "mean_rouge_score_gpt_w_lsi_rag = compute_mean_rouge_score(gpt_llm_w_rag_exact_search, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34e2cb-0284-4040-857d-f5c11c73a46b",
   "metadata": {},
   "source": [
    "##### SOTA Method (VectorDB i.e. FAISS) for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e850df31-6450-4399-8601-c3e8c1c95711",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score_gpt_w_faiss_rag = compute_mean_bleu_score(gpt_llm_w_rag_faiss, ground_truth)\n",
    "mean_rouge_score_gpt_w_faiss_rag = compute_mean_rouge_score(gpt_llm_w_rag_faiss, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "75a58b13-0906-41f0-b9fc-27d4a32ec7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With LSI RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.2721\n",
      "Mean ROUGE Score: 0.2289\n",
      "\n",
      "With VectorDB RAG:\n",
      "============\n",
      "Mean BLEU Score: 0.2906\n",
      "Mean ROUGE Score: 0.2544\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWith LSI RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_lsi_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_lsi_rag:.4f}\")\n",
    "\n",
    "print(\"\\nWith VectorDB RAG:\\n============\")\n",
    "print(f\"Mean BLEU Score: {mean_bleu_score_gpt_w_faiss_rag:.4f}\")\n",
    "print(f\"Mean ROUGE Score: {mean_rouge_score_gpt_w_faiss_rag:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
