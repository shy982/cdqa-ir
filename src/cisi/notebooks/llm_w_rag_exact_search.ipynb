{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53d450d4-a778-4e79-aee4-d061c102d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b5a6fe4-35df-4bdf-8a60-4ae947b448fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI's API key\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187e6767-aa2e-4272-aace-a07a04a9f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents' texts\n",
    "with open(\"../dataset/documents.pkl\", \"rb\") as f:\n",
    "    docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e76d74-c3a6-4f26-8e0c-a3019e136e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load queries' text\n",
    "with open(\"../dataset/queries.pkl\", \"rb\") as f:\n",
    "    queries = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7945a5b1-f59b-42a8-8313-9db9c814c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query and its most relevant documents\n",
    "with open(\"../ir_techniques/exact_search/index.pkl\", \"rb\") as f:\n",
    "    predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92610100-a442-418c-9a09-323164c73893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth\n",
    "with open(\"../dataset/rel_set.pkl\", \"rb\") as f:\n",
    "    rel_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8c11992-2bb2-4c2f-ab9c-bede9b2ff17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10  # Choose the top-k most relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303176b7-be55-4c05-93a4-92afadf7d220",
   "metadata": {},
   "source": [
    "### gpt-3.5-turbo-instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb3f52b2-dc0b-4a7c-b086-3b9f689345fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LLM\n",
    "gpt_llm = OpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84dabd52-e6df-4609-b4a7-6dc756c35308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt for the LLM\n",
    "template = \"\"\"Answer the question or Explain the topic given this additional context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "917881c1-8857-4ac1-81b8-b28fd04f08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the RAG pipeline\n",
    "gpt_chain = ({\"context\": RunnablePassthrough(), \"question\": RunnablePassthrough()} \n",
    "             | prompt \n",
    "             | gpt_llm \n",
    "             | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d06ba5e-1c0c-425b-92b7-9bed50d0b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a query\n",
    "# mquery_id = 1\n",
    "# context_str = \"\\n\\n\\n\".join([docs[doc_id][\"text\"] for doc_id in predictions[mquery_id][:k]])[:4096]\n",
    "# input_data = {\"context\": context_str, \"question\": queries[mquery_id][\"text\"]}\n",
    "# gpt_chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c8c838-2c38-4bd3-89e5-690a824d5815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking Queries to ChatGPT with RAG:   0%|                             | 0/76 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "#### API CALL WARNING #####\n",
    "\n",
    "# Run RAG pipeline for every query\n",
    "answers_gpt = {}\n",
    "for query_id in tqdm(rel_set.keys(), desc=\"Asking Queries to ChatGPT with RAG\"):\n",
    "    context_str = \"\\n\\n\\n\".join([docs[doc_id][\"text\"] for doc_id in predictions[query_id][:k]])[:4096]\n",
    "    input_data = {\"context\": context_str, \"question\": queries[query_id][\"text\"]}\n",
    "    response = gpt_chain.invoke(input_data)\n",
    "    answers_gpt[query_id] = {\"response\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4071e898-e30e-4928-bbea-493f94fe1b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?',\n",
       " \"Answer: The main concern with creating descriptive titles is that they may not accurately represent the content of the article. This can make it difficult for users to find the information they are looking for when using automated retrieval methods. The usual relevance of the content of articles to their titles is an important factor in determining the effectiveness of a citation index. This is because it allows users to quickly identify relevant articles based on the title alone, without having to read the entire article. However, this relevance can be subjective and may vary depending on the individual's search requirements and judgment.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "queries[1][\"text\"], answers_gpt[1][\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "275c28b5-fd3e-47fb-8e33-26ed42ecd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all responses\n",
    "with open(\"../responses/gpt-3.5-turbo-instruct/llm_w_rag_exact_search.pkl\", \"wb\") as f:\n",
    "    pickle.dump(answers_gpt, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
