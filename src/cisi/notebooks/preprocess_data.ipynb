{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ebac0b3-6c41-40c9-895d-767a3cecdafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import pickle\n",
    "import string\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b653b315-0651-48cc-94e7-3189e0a1ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common setup for data pre-processing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66230d62-e56e-4da0-9d31-92d076018082",
   "metadata": {},
   "source": [
    "### Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa76178-71c6-4dfe-a7ba-4cee7c5ecd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original documents\n",
    "with open(\"../dataset/original/CISI.ALL\") as f:\n",
    "    articles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18511894-622e-430d-b45d-941c740bf18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_docs(lines):\n",
    "    title_mode = False\n",
    "    body_mode = False\n",
    "    edge_mode = False\n",
    "    \n",
    "    title = \"\"\n",
    "    body = \"\"\n",
    "    \n",
    "    idx = None\n",
    "    \n",
    "    edge_str = \"\"\n",
    "    edges = []\n",
    "    docs = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for c in line:\n",
    "            if line.startswith(\".\"):\n",
    "                if line.startswith(\".I\"):\n",
    "                    for e in edge_str.split(\"\\n\"):\n",
    "                        if \"\\t\" in e:\n",
    "                            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "                    idx = int(line.split()[1])\n",
    "                    edge_str = \"\"\n",
    "                    edge_mode = False\n",
    "                    \n",
    "                if line.startswith(\".T\"):\n",
    "                    title_mode = True\n",
    "                    body_mode = False\n",
    "                    \n",
    "                elif line.startswith(\".W\"):\n",
    "                    title_mode = False\n",
    "                    body_mode = True\n",
    "                    \n",
    "                elif line.startswith(\".X\"):\n",
    "                    docs.append({\"id\": idx, \"title\": title, \"body\": body})\n",
    "                    title = \"\"\n",
    "                    body = \"\"\n",
    "                    title_mode = False\n",
    "                    body_mode = False\n",
    "                    edge_mode = True\n",
    "                    \n",
    "                else:\n",
    "                    title_mode = False\n",
    "                    body_mode = False \n",
    "                    edge_mode = False\n",
    "    \n",
    "            if title_mode:\n",
    "                title += c\n",
    "            elif body_mode:\n",
    "                body += c\n",
    "            elif edge_mode:\n",
    "                edge_str += c\n",
    "                \n",
    "    for e in edge_str.split(\"\\n\"):\n",
    "        if \"\\t\" in e:\n",
    "            edges.append((idx, int(e.split(\"\\t\")[0])))\n",
    "            \n",
    "    return [x for x in docs if x[\"title\"]], sorted(list(set(edges)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58e21e76-52e5-4cba-a4e2-261c36c5c7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract id, title, and body for each document\n",
    "d, _ = extract_docs(articles)\n",
    "docs = {x[\"id\"]: {\"text\": x[\"title\"] + \"\\n\" + x[\"body\"]} for x in d}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2bfb4b5-5b5e-4f42-acb8-dcea10dc4deb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \".T\\n18 Editions of the Dewey Decimal Classifications\\n\\n.W\\n   The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\\n\"}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "docs[1], len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bede0d0f-b9b8-4677-a98b-ca6922a9c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing (Used only for LSI)\n",
    "def clean_text(sentence):\n",
    "    # Remove punctuations\n",
    "    lookup_table = sentence.maketrans(\"\", \"\", string.punctuation)\n",
    "    clean_text = sentence.translate(lookup_table)\n",
    "\n",
    "    # Convert to lowercase and tokenize into words\n",
    "    word_list = word_tokenize(clean_text.lower())\n",
    "\n",
    "    # Remove stop-words and words with length less than or equal to 2\n",
    "    word_list = [w for w in word_list if not w in stop_words and len(w) > 2]\n",
    "\n",
    "    # Reduce each word to its lemma\n",
    "    word_list = [lemmatizer.lemmatize(word) for word in word_list]\n",
    "\n",
    "    # Convert back to sentence\n",
    "    clean_sentence = \" \".join(word_list)\n",
    "    \n",
    "    return clean_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2f3e6f-9d69-406b-a8fd-319b2cb22b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process documents\n",
    "for i, doc in docs.items():\n",
    "    docs[i][\"clean_text\"] = clean_text(doc[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fc70cc-f67a-4c8f-bfa1-810147b4bca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \".T\\n18 Editions of the Dewey Decimal Classifications\\n\\n.W\\n   The present study is a history of the DEWEY Decimal\\nClassification.  The first edition of the DDC was published\\nin 1876, the eighteenth edition in 1971, and future editions\\nwill continue to appear as needed.  In spite of the DDC's\\nlong and healthy life, however, its full story has never\\nbeen told.  There have been biographies of Dewey\\nthat briefly describe his system, but this is the first\\nattempt to provide a detailed history of the work that\\nmore than any other has spurred the growth of\\nlibrarianship in this country and abroad.\\n\",\n",
       " 'clean_text': 'edition dewey decimal classification present study history dewey decimal classification first edition ddc published 1876 eighteenth edition 1971 future edition continue appear needed spite ddc long healthy life however full story never told biography dewey briefly describe system first attempt provide detailed history work spurred growth librarianship country abroad'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707a1ee7-3ccf-43f7-a168-a7c5cdccd5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save documents to file\n",
    "with open(\"../dataset/documents.pkl\", \"wb\") as f:\n",
    "    pickle.dump(docs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab04527-e123-40e3-b84a-a948d2b58483",
   "metadata": {},
   "source": [
    "### Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f716a2c-2d42-4402-9e85-bdec15d4af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c023b7-edc0-4259-b328-d8c02c1d0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original queries\n",
    "idx = None\n",
    "with open(\"../dataset/original/CISI.QRY\") as f:\n",
    "    for query in f.read().split(\".I\"):\n",
    "        for i, line in enumerate(query.split(\"\\n\")):\n",
    "            if not line:\n",
    "                continue\n",
    "            elif i == 0:\n",
    "                idx = int(line)\n",
    "                queries[idx] = {\"text\": \"\"}\n",
    "            elif not line.startswith(\".\"):\n",
    "                queries[idx][\"text\"] += \" \" + line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd1f39fb-6cad-42ca-943d-f8fc68ba2833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "queries[1], len(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d450a9f9-b61e-4546-b369-55741d3b8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process queries\n",
    "for i, query in queries.items():\n",
    "    queries[i][\"clean_text\"] = clean_text(query[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d55f19a9-3e4b-45d4-874a-ca7cf6ba4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?',\n",
       " 'clean_text': 'problem concern making descriptive title difficulty involved automatically retrieving article approximate title usual relevance content article title'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "queries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb8f67b-9408-493b-9ee4-fe78c4be5ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save queries to file\n",
    "with open(\"../dataset/queries.pkl\", \"wb\") as f:\n",
    "    pickle.dump(queries, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093c27c9-5453-4f20-b6c6-fb924ca827bf",
   "metadata": {},
   "source": [
    "### Relevance Set (Ground Truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f892c31b-1173-45ce-98f6-dbe4eda859cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original relevance set\n",
    "with open(\"../dataset/original/CISI.REL\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d46296a-d449-437f-8c38-0b5c749248a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/original/CISI.REL\") as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "    ground_truth = [[]]*len(lines)\n",
    "    for line in lines:\n",
    "        clean_line = line.strip().replace('\\t',' ').split()\n",
    "        query, doc = [int(num.replace(' ','')) for num in clean_line[:2]]\n",
    "        ground_truth[query].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0884c850-43b5-44a4-bdd9-578b57fd9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ground truth documents for each query\n",
    "ground_truth = defaultdict(list)\n",
    "for line in lines:\n",
    "    clean_line = line.strip().replace('\\t',' ').split()\n",
    "    query, doc = [int(num.replace(' ','')) for num in clean_line[:2]]\n",
    "    ground_truth[query].append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38294276-0d59-4522-961d-0af83922dd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "final_dict = dict(enumerate(ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67299b86-6056-4f36-9ee8-cc0ca87b5749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3114"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "156c964b-32bf-4f11-b70f-a34d78be07fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save relevance set to file\n",
    "with open(\"../dataset/rel_set.pkl\", \"wb\") as f:\n",
    "    pickle.dump(final_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622c49a7-05c5-4569-8405-93220f05b9da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
